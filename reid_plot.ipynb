{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import torchvision.transforms as T\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import tensorrt as trt\n",
    "import torchreid\n",
    "from torch2trt import torch2trt\n",
    "from torchreid.utils import FeatureExtractor\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.015953063964844\n"
     ]
    }
   ],
   "source": [
    "pixel_mean=[0.485, 0.456, 0.406]\n",
    "pixel_std=[0.229, 0.224, 0.225]\n",
    "paths = []\n",
    "seuil = 12.0\n",
    "min_dist = 2.46\n",
    "max_dist = 15\n",
    "fiablility = 100-(((distance-min_dist)/(max_dist-min_dist))*100)\n",
    "preprocess = T.Compose([T.Resize((256,128)),\n",
    "                        T.ToTensor(),\n",
    "                        T.Normalize(mean=pixel_mean, std=pixel_std)])\n",
    "\n",
    "def preprocess_and_infer(path_to_img):\n",
    "        \n",
    "        image = Image.open(path_to_img).convert('RGB')\n",
    "        paths.append(image)\n",
    "        image = preprocess(image)\n",
    "        images = image.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            features = model(images)\n",
    "\n",
    "        return features\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\": \n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.parse_args()\n",
    "    \n",
    "    model = torch.load('extractor_osnet_x1.pth') \n",
    "    model.eval()\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "    \n",
    "    features = preprocess_and_infer(\"test.jpg\")\n",
    "    features2 = preprocess_and_infer(\"test2.jpg\")\n",
    "    distance = float(torch.dist(features,features2))\n",
    "    print(distance)\n",
    "    \n",
    "    figure = plt.figure()\n",
    "    figure.add_subplot(1,2, 1)\n",
    "    plt.imshow(paths[0])\n",
    "    figure.add_subplot(1,2, 2)\n",
    "    plt.imshow(paths[1])\n",
    "    \n",
    "    if distance > seuil:\n",
    "        figure.suptitle('no reID')\n",
    "        plt.savefig('./results/output_.png')\n",
    "    else:\n",
    "        figure.suptitle('reID precision : '+str(round(100-(((distance-min_dist)/(max_dist-min_dist))*100),2))+' %')\n",
    "        plt.savefig('./results/output_.png')\n",
    "    \n",
    "    plt.close(figure)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
